{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features finales : 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 11:42:34,288] A new study created in memory with name: no-name-b150637d-1a5e-4902-afd5-c69db42127b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Optuna tuning LightGBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's auc: 0.843585 + 0.000480936\n",
      "[400]\tvalid's auc: 0.85569 + 0.000954555\n",
      "[600]\tvalid's auc: 0.861167 + 0.000993331\n",
      "[800]\tvalid's auc: 0.864367 + 0.00107739\n",
      "[1000]\tvalid's auc: 0.866463 + 0.00103248\n",
      "[1200]\tvalid's auc: 0.868093 + 0.0011511\n",
      "[1400]\tvalid's auc: 0.869222 + 0.00108625\n",
      "[1600]\tvalid's auc: 0.870049 + 0.00104987\n",
      "[1800]\tvalid's auc: 0.870748 + 0.000974653\n",
      "[2000]\tvalid's auc: 0.871347 + 0.000944506\n",
      "[2200]\tvalid's auc: 0.871804 + 0.000928164\n",
      "[2400]\tvalid's auc: 0.872225 + 0.000900202\n",
      "[2600]\tvalid's auc: 0.872535 + 0.000925801\n",
      "[2800]\tvalid's auc: 0.872812 + 0.00086406\n",
      "[3000]\tvalid's auc: 0.873074 + 0.000845381\n",
      "[3200]\tvalid's auc: 0.873231 + 0.00084837\n",
      "[3400]\tvalid's auc: 0.873409 + 0.000812699\n",
      "[3600]\tvalid's auc: 0.873578 + 0.000767851\n",
      "[3800]\tvalid's auc: 0.873701 + 0.000768022\n",
      "[4000]\tvalid's auc: 0.873814 + 0.000784611\n",
      "[4200]\tvalid's auc: 0.873865 + 0.000858777\n",
      "[4400]\tvalid's auc: 0.873915 + 0.000878409\n",
      "[4600]\tvalid's auc: 0.873969 + 0.000876082\n",
      "[4800]\tvalid's auc: 0.874008 + 0.000857115\n",
      "[5000]\tvalid's auc: 0.874027 + 0.000843076\n",
      "[5200]\tvalid's auc: 0.874101 + 0.000849421\n",
      "[5400]\tvalid's auc: 0.874106 + 0.000867331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.874107:  14%|#4        | 1/7 [04:31<27:09, 271.51s/it][I 2025-06-04 11:47:05,799] Trial 0 finished with value: 0.8741071732770184 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8741071732770184.\n",
      "feature_fraction, val_score: 0.874107:  14%|#4        | 1/7 [04:31<27:09, 271.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5390]\tvalid's auc: 0.874107 + 0.000861722\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's auc: 0.842124 + 0.000979402\n",
      "[400]\tvalid's auc: 0.854267 + 0.0013537\n",
      "[600]\tvalid's auc: 0.859809 + 0.00114546\n",
      "[800]\tvalid's auc: 0.863031 + 0.00103116\n",
      "[1000]\tvalid's auc: 0.865198 + 0.000912375\n",
      "[1200]\tvalid's auc: 0.86687 + 0.000905311\n",
      "[1400]\tvalid's auc: 0.867955 + 0.000840021\n",
      "[1600]\tvalid's auc: 0.86899 + 0.000808273\n",
      "[1800]\tvalid's auc: 0.869695 + 0.00074907\n",
      "[2000]\tvalid's auc: 0.870394 + 0.000758287\n",
      "[2200]\tvalid's auc: 0.870947 + 0.000762677\n",
      "[2400]\tvalid's auc: 0.871488 + 0.000862418\n",
      "[2600]\tvalid's auc: 0.871869 + 0.000876528\n",
      "[2800]\tvalid's auc: 0.872253 + 0.000892153\n",
      "[3000]\tvalid's auc: 0.872501 + 0.000836589\n",
      "[3200]\tvalid's auc: 0.872735 + 0.00080807\n",
      "[3400]\tvalid's auc: 0.872929 + 0.000827841\n",
      "[3600]\tvalid's auc: 0.873077 + 0.000794973\n",
      "[3800]\tvalid's auc: 0.873228 + 0.000808616\n",
      "[4000]\tvalid's auc: 0.873334 + 0.000818302\n",
      "[4200]\tvalid's auc: 0.873426 + 0.00078748\n",
      "[4400]\tvalid's auc: 0.873516 + 0.000777977\n",
      "[4600]\tvalid's auc: 0.87362 + 0.000759493\n",
      "[4800]\tvalid's auc: 0.87371 + 0.000752639\n",
      "[5000]\tvalid's auc: 0.873735 + 0.000769421\n",
      "[5200]\tvalid's auc: 0.873805 + 0.000761162\n",
      "[5400]\tvalid's auc: 0.873852 + 0.000745293\n",
      "[5600]\tvalid's auc: 0.87388 + 0.000720989\n",
      "[5800]\tvalid's auc: 0.873919 + 0.000712308\n",
      "[6000]\tvalid's auc: 0.873949 + 0.000710731\n",
      "[6200]\tvalid's auc: 0.873977 + 0.000720241\n",
      "[6400]\tvalid's auc: 0.873977 + 0.000724978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.874107:  29%|##8       | 2/7 [10:33<27:02, 324.60s/it][I 2025-06-04 11:53:07,565] Trial 1 finished with value: 0.8739843015987298 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8741071732770184.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6243]\tvalid's auc: 0.873984 + 0.000731532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.874107:  29%|##8       | 2/7 [10:33<27:02, 324.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's auc: 0.842161 + 0.000831851\n",
      "[400]\tvalid's auc: 0.85406 + 0.00127011\n",
      "[600]\tvalid's auc: 0.859232 + 0.00103704\n",
      "[800]\tvalid's auc: 0.862542 + 0.00116237\n",
      "[1000]\tvalid's auc: 0.864745 + 0.00104094\n",
      "[1200]\tvalid's auc: 0.866395 + 0.00088719\n",
      "[1400]\tvalid's auc: 0.867597 + 0.000909247\n",
      "[1600]\tvalid's auc: 0.868547 + 0.000798246\n",
      "[1800]\tvalid's auc: 0.869314 + 0.000793793\n",
      "[2000]\tvalid's auc: 0.869993 + 0.000778508\n",
      "[2200]\tvalid's auc: 0.87058 + 0.000805785\n",
      "[2400]\tvalid's auc: 0.87109 + 0.0007802\n",
      "[2600]\tvalid's auc: 0.871536 + 0.000750728\n",
      "[2800]\tvalid's auc: 0.871866 + 0.000689093\n",
      "[3000]\tvalid's auc: 0.872171 + 0.000685924\n",
      "[3200]\tvalid's auc: 0.872448 + 0.000712427\n",
      "[3400]\tvalid's auc: 0.872736 + 0.000704434\n",
      "[3600]\tvalid's auc: 0.8729 + 0.000657846\n",
      "[3800]\tvalid's auc: 0.873067 + 0.000619138\n",
      "[4000]\tvalid's auc: 0.873222 + 0.000629951\n",
      "[4200]\tvalid's auc: 0.873332 + 0.000649273\n",
      "[4400]\tvalid's auc: 0.873445 + 0.000656838\n",
      "[4600]\tvalid's auc: 0.873552 + 0.000674983\n",
      "[4800]\tvalid's auc: 0.873631 + 0.00067633\n",
      "[5000]\tvalid's auc: 0.873685 + 0.000667682\n",
      "[5200]\tvalid's auc: 0.873747 + 0.000690927\n",
      "[5400]\tvalid's auc: 0.873763 + 0.000699092\n",
      "[5600]\tvalid's auc: 0.873767 + 0.000679673\n",
      "[5800]\tvalid's auc: 0.873805 + 0.000672482\n",
      "[6000]\tvalid's auc: 0.873823 + 0.000682497\n",
      "[6200]\tvalid's auc: 0.873873 + 0.00069295\n",
      "[6400]\tvalid's auc: 0.873878 + 0.000663168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.874107:  43%|####2     | 3/7 [17:22<24:13, 363.33s/it][I 2025-06-04 11:59:56,979] Trial 2 finished with value: 0.8738887944105439 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.8741071732770184.\n",
      "feature_fraction, val_score: 0.874107:  43%|####2     | 3/7 [17:22<24:13, 363.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6301]\tvalid's auc: 0.873889 + 0.000671793\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's auc: 0.843146 + 0.00113934\n",
      "[400]\tvalid's auc: 0.85501 + 0.00143863\n",
      "[600]\tvalid's auc: 0.860494 + 0.00109961\n",
      "[800]\tvalid's auc: 0.863609 + 0.000982443\n",
      "[1000]\tvalid's auc: 0.865863 + 0.00098619\n",
      "[1200]\tvalid's auc: 0.867411 + 0.00102219\n",
      "[1400]\tvalid's auc: 0.868547 + 0.00109691\n",
      "[1600]\tvalid's auc: 0.869508 + 0.0010216\n",
      "[1800]\tvalid's auc: 0.870263 + 0.00093042\n",
      "[2000]\tvalid's auc: 0.870932 + 0.000923264\n",
      "[2200]\tvalid's auc: 0.871428 + 0.00088891\n",
      "[2400]\tvalid's auc: 0.871837 + 0.00084634\n",
      "[2600]\tvalid's auc: 0.872213 + 0.000816838\n",
      "[2800]\tvalid's auc: 0.872461 + 0.000818362\n",
      "[3000]\tvalid's auc: 0.872762 + 0.000792672\n",
      "[3200]\tvalid's auc: 0.872974 + 0.000807293\n",
      "[3400]\tvalid's auc: 0.873134 + 0.000810242\n",
      "[3600]\tvalid's auc: 0.873314 + 0.000787942\n",
      "[3800]\tvalid's auc: 0.873505 + 0.000831391\n",
      "[4000]\tvalid's auc: 0.873685 + 0.000795085\n",
      "[4200]\tvalid's auc: 0.873783 + 0.000841081\n",
      "[4400]\tvalid's auc: 0.873886 + 0.000878508\n",
      "[4600]\tvalid's auc: 0.874008 + 0.000887649\n",
      "[4800]\tvalid's auc: 0.874029 + 0.000856731\n",
      "[5000]\tvalid's auc: 0.874081 + 0.000849301\n",
      "[5200]\tvalid's auc: 0.874111 + 0.000843938\n",
      "[5400]\tvalid's auc: 0.874146 + 0.000833071\n",
      "[5600]\tvalid's auc: 0.874184 + 0.00081981\n",
      "[5800]\tvalid's auc: 0.874214 + 0.000809172\n",
      "[6000]\tvalid's auc: 0.874238 + 0.000815909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.874243:  57%|#####7    | 4/7 [22:38<17:13, 344.50s/it][I 2025-06-04 12:05:12,604] Trial 3 finished with value: 0.8742430723457704 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 0.8742430723457704.\n",
      "feature_fraction, val_score: 0.874243:  57%|#####7    | 4/7 [22:38<17:13, 344.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5951]\tvalid's auc: 0.874243 + 0.000821072\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's auc: 0.83955 + 0.000996415\n",
      "[400]\tvalid's auc: 0.851256 + 0.00115059\n",
      "[600]\tvalid's auc: 0.856942 + 0.00111254\n",
      "[800]\tvalid's auc: 0.860357 + 0.00110288\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# kaggle_pipeline_lgb_optuna.py\n",
    "# ===========================================\n",
    "# ▶ Avant de lancer :\n",
    "#   pip install lightgbm optuna category_encoders\n",
    "#   (GPU : pip install lightgbm-gpu)\n",
    "# ===========================================\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import optuna.integration.lightgbm as lgb_optuna\n",
    "import lightgbm as lgb\n",
    "# import category_encoders as ce   # pour le frequency encoding\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Chargement\n",
    "# ------------------------------------------------------------------------------\n",
    "DATA_DIR = Path(\".\")        # ajuste si nécessaire\n",
    "TRAIN_CSV = DATA_DIR / \"train.csv\"\n",
    "TEST_CSV  = DATA_DIR / \"test.csv\"\n",
    "SUB_CSV   = DATA_DIR / \"testSubmissionFile.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_CSV)\n",
    "test  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Feature engineering\n",
    "# ------------------------------------------------------------------------------\n",
    "def add_datetime_features(df: pd.DataFrame, ts_col: str = \"timeStamp\") -> pd.DataFrame:\n",
    "    \"\"\"Ajoute les features calendaires + cycliques, puis supprime la colonne brute.\"\"\"\n",
    "    dt = pd.to_datetime(df[ts_col], unit=\"s\")\n",
    "    df[\"year\"]       = dt.dt.year\n",
    "    df[\"month\"]      = dt.dt.month\n",
    "    df[\"day\"]        = dt.dt.day\n",
    "    df[\"hour\"]       = dt.dt.hour\n",
    "    df[\"dayofweek\"]  = dt.dt.dayofweek          # 0 = lundi\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(\"int8\")\n",
    "\n",
    "    # encode cyclique (sin/cos) pour month / dayofweek / hour\n",
    "    df[\"hour_sin\"]  = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"]  = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "\n",
    "    df[\"dow_sin\"]   = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "    df[\"dow_cos\"]   = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "    return df.drop(columns=[ts_col])\n",
    "\n",
    "\n",
    "def frequency_encode(train_series: pd.Series,\n",
    "                     test_series: pd.Series,\n",
    "                     min_count: int = 10) -> tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Encode une variable catégorielle par la fréquence de chaque modalité.\n",
    "    Pour les modalités très rares (< min_count) on met la même valeur.\n",
    "    \"\"\"\n",
    "    freq = train_series.value_counts()\n",
    "    rare_mask = freq < min_count\n",
    "    freq[rare_mask] = min_count          # lissage simple\n",
    "    freq_enc = freq / freq.sum()\n",
    "\n",
    "    return train_series.map(freq_enc).fillna(0), test_series.map(freq_enc).fillna(0)\n",
    "\n",
    "\n",
    "def preprocess(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    \"\"\" Nettoyage, features, encodage. Retour : X_train, X_test, y, cat_features \"\"\"\n",
    "    # --- cibles et identifiants ------------------------------------------------\n",
    "    y = train_df[\"isSold\"].copy()\n",
    "    train_df = train_df.drop(columns=[\"isSold\"])\n",
    "\n",
    "    test_ids = test_df[\"auctionId\"].copy()\n",
    "\n",
    "    # Conserver auctionId pour soumission uniquement\n",
    "    train_df = train_df.drop(columns=[\"auctionId\"])\n",
    "    test_df  = test_df.drop(columns=[\"auctionId\"])\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 2.1. Features temporelles\n",
    "    train_df = add_datetime_features(train_df)\n",
    "    test_df  = add_datetime_features(test_df)\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 2.2. Large cardinality : frequency encoding\n",
    "    hi_card_cols = [\n",
    "        \"hashedRefererDeepThree\",\n",
    "        \"placementId\",\n",
    "        \"websiteId\",\n",
    "        \"browserVersion\"\n",
    "    ]\n",
    "\n",
    "    for col in hi_card_cols:\n",
    "        if col in train_df.columns:\n",
    "            tr_enc, te_enc = frequency_encode(train_df[col], test_df[col])\n",
    "            train_df[f\"{col}_freq\"] = tr_enc\n",
    "            test_df[f\"{col}_freq\"]  = te_enc\n",
    "\n",
    "            # on retire la version brute (si on ne veut pas la passer en cat)\n",
    "            train_df = train_df.drop(columns=[col])\n",
    "            test_df  = test_df.drop(columns=[col])\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 2.3. Colonnes catégorielles « propres » (faible / moyenne cardinalité)\n",
    "    cat_cols = [\n",
    "        \"country\",\n",
    "        \"opeartingSystem\",\n",
    "        \"browser\",\n",
    "        \"device\",\n",
    "        \"environmentType\",\n",
    "        \"articleSafenessCategorization\",\n",
    "        \"year\",        # même année ? on peut laisser en num ou cat\n",
    "        # month/day/hour seraient plutôt conservés comme num + cyc\n",
    "    ]\n",
    "    cat_cols = [c for c in cat_cols if c in train_df.columns]\n",
    "\n",
    "    # LightGBM veut dtype category\n",
    "    for col in cat_cols:\n",
    "        train_df[col] = train_df[col].astype(\"category\")\n",
    "        test_df[col]  = test_df[col].astype(\"category\")\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 2.4. Normalisation éventuelle (pas nécessaire pour LightGBM)\n",
    "    # ----------------------------------------------------------------------------\n",
    "    print(f\"Features finales : {train_df.shape[1]}\")\n",
    "\n",
    "    return train_df, test_df, y, test_ids, cat_cols\n",
    "\n",
    "\n",
    "X_train_full, X_test_full, y_full, test_ids, cat_features = preprocess(train.copy(),\n",
    "                                                                       test.copy())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Split train/validation\n",
    "# ------------------------------------------------------------------------------\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Optuna : LightGBM hyper-parameter search\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n=== Optuna tuning LightGBM ===\")\n",
    "\n",
    "# LightGBMTunerCV gère la CV interne + early stopping\n",
    "lgb_train = lgb.Dataset(X_tr, y_tr, categorical_feature=cat_features, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_val, y_val, reference=lgb_train, categorical_feature=cat_features,\n",
    "                        free_raw_data=False)\n",
    "\n",
    "base_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"feature_pre_filter\": False,     # garder toutes les features\n",
    "    \"seed\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    # GPU : décommente si dispo\n",
    "    # \"device\": \"gpu\",\n",
    "    # \"gpu_platform_id\": 0,\n",
    "    # \"gpu_device_id\": 0,\n",
    "}\n",
    "\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "tuner = lgb_optuna.LightGBMTunerCV(\n",
    "    params        = base_params,\n",
    "    train_set     = lgb_train,\n",
    "    folds         = StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    num_boost_round = 10_000,\n",
    "    callbacks     = [\n",
    "        early_stopping(stopping_rounds=200),\n",
    "        log_evaluation(period=200),\n",
    "    ],\n",
    ")\n",
    "\n",
    "tuner.run()            # recherche bayésienne\n",
    "\n",
    "best_params = tuner.best_params\n",
    "best_score  = tuner.best_score\n",
    "print(f\"Best AUC (CV) : {best_score:.5f}\")\n",
    "print(\"Best params :\", best_params)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Ré-entraînement sur le full training set avec les meilleurs paramètres\n",
    "# ------------------------------------------------------------------------------\n",
    "best_params.update({\"metric\": \"auc\", \"objective\": \"binary\", \"verbosity\": -1})\n",
    "full_dataset = lgb.Dataset(X_train_full, y_full, categorical_feature=cat_features)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    full_dataset,\n",
    "    num_boost_round = tuner.best_iteration\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6. Validation offline (val set)\n",
    "# ------------------------------------------------------------------------------\n",
    "val_pred = final_model.predict(X_val)\n",
    "offline_auc = roc_auc_score(y_val, val_pred)\n",
    "print(f\"Validation AUC (hold-out) : {offline_auc:.5f}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 7. Prédiction test + soumission\n",
    "# ------------------------------------------------------------------------------\n",
    "test_pred = final_model.predict(X_test_full)\n",
    "submission = pd.DataFrame({\"auctionId\": test_ids, \"isSold\": test_pred})\n",
    "SUB_PATH = DATA_DIR / \"submission_lgb_optuna.csv\"\n",
    "submission.to_csv(SUB_PATH, index=False)\n",
    "print(f\"✅ Submission sauvegardée → {SUB_PATH.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
